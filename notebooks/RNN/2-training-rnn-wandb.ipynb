{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from evaluation import evaluate\n",
    "from training_utils import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch import optim\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_dict = utils.open_object(\"./artifacts/feature_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {}\n",
    "config_dict['window_size'] = 24\n",
    "config_dict['learning_rate'] = 0.0002\n",
    "config_dict['batch_size'] = 12\n",
    "config_dict['epochs'] = 200\n",
    "config_dict['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config_dict['input_size'] = 5\n",
    "config_dict['hidden_size'] = 32\n",
    "config_dict['output_size'] = config_dict['input_size']\n",
    "config_dict['lstm_num_layers'] = 3\n",
    "config_dict['dropout'] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = \"QQQ Stock Price Prediction Based On LSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = f\"window_size:{config_dict['window_size']} batch_size:{config_dict['batch_size']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnelsonlin0321\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nelsonlin/Desktop/WorkSpace/ml-stock-price-forecasting/notebooks/RNN/wandb/run-20231219_002959-8zn51p33</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM/runs/8zn51p33' target=\"_blank\">window_size:24 batch_size:12</a></strong> to <a href='https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM' target=\"_blank\">https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM/runs/8zn51p33' target=\"_blank\">https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM/runs/8zn51p33</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/nelsonlin0321/QQQ%20Stock%20Price%20Prediction%20Based%20On%20LSTM/runs/8zn51p33?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x286006a10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=wandb_project,\n",
    "    job_type=\"train\",\n",
    "    config=config_dict,\n",
    "    name=display_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, dictionary):\n",
    "        for key, value in dictionary.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "\n",
    "config = Config(dictionary=config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./artifacts/processed_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>0.481644</td>\n",
       "      <td>0.480709</td>\n",
       "      <td>0.481546</td>\n",
       "      <td>0.479795</td>\n",
       "      <td>0.028304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>0.481644</td>\n",
       "      <td>0.480709</td>\n",
       "      <td>0.481156</td>\n",
       "      <td>0.479990</td>\n",
       "      <td>0.071394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>0.484156</td>\n",
       "      <td>0.483017</td>\n",
       "      <td>0.485037</td>\n",
       "      <td>0.485023</td>\n",
       "      <td>0.129351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>0.489107</td>\n",
       "      <td>0.485494</td>\n",
       "      <td>0.487338</td>\n",
       "      <td>0.487883</td>\n",
       "      <td>0.139565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>0.493593</td>\n",
       "      <td>0.490750</td>\n",
       "      <td>0.492627</td>\n",
       "      <td>0.490523</td>\n",
       "      <td>0.096587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      open      high       low     close    volume\n",
       "0  1999-11-01  0.481644  0.480709  0.481546  0.479795  0.028304\n",
       "1  1999-11-02  0.481644  0.480709  0.481156  0.479990  0.071394\n",
       "2  1999-11-03  0.484156  0.483017  0.485037  0.485023  0.129351\n",
       "3  1999-11-04  0.489107  0.485494  0.487338  0.487883  0.139565\n",
       "4  1999-11-05  0.493593  0.490750  0.492627  0.490523  0.096587"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cols = [\"volume\", \"high\", \"low\", \"open\", \"close\"]\n",
    "\n",
    "df_data = df[features_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028304</td>\n",
       "      <td>0.480709</td>\n",
       "      <td>0.481546</td>\n",
       "      <td>0.481644</td>\n",
       "      <td>0.479795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071394</td>\n",
       "      <td>0.480709</td>\n",
       "      <td>0.481156</td>\n",
       "      <td>0.481644</td>\n",
       "      <td>0.479990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129351</td>\n",
       "      <td>0.483017</td>\n",
       "      <td>0.485037</td>\n",
       "      <td>0.484156</td>\n",
       "      <td>0.485023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139565</td>\n",
       "      <td>0.485494</td>\n",
       "      <td>0.487338</td>\n",
       "      <td>0.489107</td>\n",
       "      <td>0.487883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096587</td>\n",
       "      <td>0.490750</td>\n",
       "      <td>0.492627</td>\n",
       "      <td>0.493593</td>\n",
       "      <td>0.490523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     volume      high       low      open     close\n",
       "0  0.028304  0.480709  0.481546  0.481644  0.479795\n",
       "1  0.071394  0.480709  0.481156  0.481644  0.479990\n",
       "2  0.129351  0.483017  0.485037  0.484156  0.485023\n",
       "3  0.139565  0.485494  0.487338  0.489107  0.487883\n",
       "4  0.096587  0.490750  0.492627  0.493593  0.490523"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df_data))\n",
    "df_train = df_data[:train_size]\n",
    "df_test = df_data[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Create Sequence of input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = torch.tensor(\n",
    "            self.data[idx:idx+self.window_size], dtype=torch.float32)\n",
    "        target = torch.tensor(\n",
    "            self.data[idx+self.window_size], dtype=torch.float32)\n",
    "        return inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(\n",
    "    data=df_train.values, window_size=config.window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataset(\n",
    "    data=df_test.values, window_size=config.window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, config.batch_size,\n",
    "                          shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 24, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape  # batch_size, sequence_len, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape  # batch_size, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, lstm_num_layers, hidden_size, output_size, device):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            num_layers=lstm_num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2*self.lstm_num_layers, x.size(0), self.hidden_size).to(\n",
    "            self.device)\n",
    "        c0 = torch.zeros(2*self.lstm_num_layers, x.size(0), self.hidden_size).to(\n",
    "            self.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTMModel(input_size=config.input_size, lstm_num_layers=config.lstm_num_layers,\n",
    "                    hidden_size=config.hidden_size, output_size=config.output_size,\n",
    "                    device=config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(config.batch_size, config.window_size, config.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0627)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(out, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0706)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(out[:, -1], targets[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class self:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = config.input_size\n",
    "# lstm_num_layers = config.lstm_num_layers\n",
    "# hidden_size = config.hidden_size\n",
    "# output_size = config.output_size\n",
    "# device = config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.device = device\n",
    "# self.lstm_num_layers = lstm_num_layers\n",
    "# self.hidden_size = hidden_size\n",
    "# self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "#                     num_layers=lstm_num_layers, batch_first=True, bidirectional=True)\n",
    "# self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "# self.sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h0 = torch.zeros(2*self.lstm_num_layers, x.size(0), self.hidden_size).to(\n",
    "#     self.device)\n",
    "# c0 = torch.zeros(2*self.lstm_num_layers, x.size(0), self.hidden_size).to(\n",
    "#     self.device)\n",
    "# out, _ = self.lstm(x, (h0, c0))\n",
    "# out = self.fc(out[:, -1, :])\n",
    "# out = self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = criterion(out, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion(out[:, -1], targets[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler_dict['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 155.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03720933845732361,\n",
       " 'eval_price_loss': 0.042895716964267194,\n",
       " 'eval_MEA': 161.55112}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model=model, test_loader=test_loader,\n",
    "         scaler=scaler, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "best_eval_loss = float(\"inf\")\n",
    "model_version = \"v1\"\n",
    "metrics_list = []\n",
    "best_model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 287.43it/s]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 234.61it/s]val_loss=0.0366, eval_price_loss=0.0473, eval_MEA=168, best_eval_loss=0.0366, train_loss=0.0174, train_price_loss=0.0189, train_MAE=29.3, epoch=0, best_epoch=0]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 301.36it/s]eval_loss=0.0167, eval_price_loss=0.0226, eval_MEA=127, best_eval_loss=0.0167, train_loss=0.0015, train_price_loss=0.0009, train_MAE=5.83, epoch=1, best_epoch=1]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 317.88it/s]eval_loss=0.0135, eval_price_loss=0.0173, eval_MEA=113, best_eval_loss=0.0135, train_loss=0.0011, train_price_loss=0.0003, train_MAE=3.12, epoch=2, best_epoch=2]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 336.13it/s]eval_loss=0.0125, eval_price_loss=0.0157, eval_MEA=109, best_eval_loss=0.0125, train_loss=0.001, train_price_loss=0.0002, train_MAE=2.65, epoch=3, best_epoch=3] \n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 228.10it/s]eval_loss=0.0129, eval_price_loss=0.0159, eval_MEA=110, best_eval_loss=0.0125, train_loss=0.001, train_price_loss=0.0002, train_MAE=2.41, epoch=4, best_epoch=3]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 324.01it/s]eval_loss=0.0116, eval_price_loss=0.0138, eval_MEA=103, best_eval_loss=0.0116, train_loss=0.001, train_price_loss=0.0001, train_MAE=2.24, epoch=5, best_epoch=5]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 330.81it/s]eval_loss=0.0112, eval_price_loss=0.0132, eval_MEA=101, best_eval_loss=0.0112, train_loss=0.0009, train_price_loss=0.0001, train_MAE=2.3, epoch=6, best_epoch=6]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 311.99it/s]eval_loss=0.0107, eval_price_loss=0.0126, eval_MEA=99.9, best_eval_loss=0.0107, train_loss=0.0009, train_price_loss=0.0001, train_MAE=2.1, epoch=7, best_epoch=7]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 320.92it/s]eval_loss=0.0097, eval_price_loss=0.011, eval_MEA=93.7, best_eval_loss=0.0097, train_loss=0.0008, train_price_loss=0.0001, train_MAE=1.98, epoch=8, best_epoch=8]\n",
      "Evaluating:: 100%|██████████| 100/100 [00:00<00:00, 344.57it/s]eval_loss=0.0079, eval_price_loss=0.0087, eval_MEA=84.5, best_eval_loss=0.0079, train_loss=0.0007, train_price_loss=0.0001, train_MAE=1.93, epoch=9, best_epoch=9]\n",
      "Training:   6%|▌         | 4771/80400 [01:15<21:27, 58.73it/s, eval_loss=0.0062, eval_price_loss=0.0066, eval_MEA=74.4, best_eval_loss=0.0062, train_loss=0.0006, train_price_loss=0.0001, train_MAE=1.86, epoch=10, best_epoch=10]"
     ]
    }
   ],
   "source": [
    "total_pbar = tqdm(total=len(train_loader)*config.epochs,\n",
    "                  desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "\n",
    "    train_loss_list = []\n",
    "    price_loss_list = []\n",
    "    prediction_list = []\n",
    "    ground_truth_list = []\n",
    "\n",
    "    model = model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        price_loss = criterion(outputs[:, -1], targets[:, -1])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_list.append(loss.item())\n",
    "        price_loss_list.append(price_loss.item())\n",
    "\n",
    "        yhat = outputs[:, -1].detach().cpu().numpy()\n",
    "        prediction_list.append(yhat)\n",
    "\n",
    "        y = targets[:, -1].detach().cpu().numpy()\n",
    "        ground_truth_list.append(y)\n",
    "\n",
    "        total_pbar.update(1)\n",
    "\n",
    "    improve = False\n",
    "    model_metrics = evaluate(\n",
    "        model, test_loader, scaler, criterion)\n",
    "    eval_loss = model_metrics['eval_loss']\n",
    "\n",
    "    if eval_loss <= best_eval_loss:\n",
    "        improve = True\n",
    "        best_checkpoint = epoch\n",
    "        best_eval_loss = eval_loss\n",
    "\n",
    "    train_loss = np.mean(train_loss_list)\n",
    "    train_price_loss = np.mean(price_loss_list)\n",
    "\n",
    "    predictions = np.concatenate(prediction_list)\n",
    "    ground_truths = np.concatenate(ground_truth_list)\n",
    "\n",
    "    predictions = np.exp(scaler.inverse_transform(\n",
    "        predictions.reshape(-1, 1)))[:, 0]\n",
    "    ground_truths = np.exp(scaler.inverse_transform(\n",
    "        ground_truths.reshape(-1, 1)))[:, 0]\n",
    "\n",
    "    mae = metrics.mean_absolute_error(ground_truths, predictions)\n",
    "    model_metrics['best_eval_loss'] = best_eval_loss\n",
    "\n",
    "    model_metrics['train_loss'] = train_loss\n",
    "    model_metrics['train_price_loss'] = train_price_loss\n",
    "    model_metrics['train_MAE'] = mae\n",
    "\n",
    "    model_metrics[\"epoch\"] = epoch\n",
    "    model_metrics[\"best_epoch\"] = best_checkpoint\n",
    "    metrics_list.append(model_metrics)\n",
    "    # wandb.log(model_metrics)\n",
    "\n",
    "    if improve:\n",
    "        save_dir = os.path.join(\"models\", model_version)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        model_path = save_model(model, save_dir, epoch, model_metrics)\n",
    "        best_model_path = model_path\n",
    "\n",
    "    post_fix_message = {k: round(v, 4) for k, v in model_metrics.items()}\n",
    "    total_pbar.set_postfix(post_fix_message)\n",
    "\n",
    "\n",
    "total_pbar.close()\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
